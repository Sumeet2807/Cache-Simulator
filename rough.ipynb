{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq as h\n",
    "import numpy as np\n",
    "\n",
    "POISSON_PROCESS_NEW_REQUESTS_LAMBDA = 100\n",
    "PARETO_PROCESS_NEW_FILE_SIZE_A = 1\n",
    "PARETO_PROCESS_FILE_POPULARITY_A = 1\n",
    "LOGNORMAL_PROCESS_ARRIVE_AT_QUEUE_MEAN = 0.5\n",
    "LOGNORMAL_PROCESS_ARRIVE_AT_QUEUE_SIGMA = 0.4\n",
    "\n",
    "TOTAL_NO_OF_FILES = 1000\n",
    "INSTITUTIONAL_BANDWIDTH = 1000\n",
    "ACCESS_LINK_BANDWIDTH = 15\n",
    "TOTAL_TIME_TO_RUN = 1000\n",
    "CACHE_CAPACITY = 10\n",
    "CACHE_MAX_ALLOWED_FILE_SIZE = 10\n",
    "\n",
    "\n",
    "class Files:\n",
    "    def __init__(self):\n",
    "        self.popularity = np.random.pareto(PARETO_PROCESS_FILE_POPULARITY_A,size=TOTAL_NO_OF_FILES)\n",
    "        self.popularity = self.popularity/np.sum(self.popularity)\n",
    "        self.size = np.random.pareto(PARETO_PROCESS_NEW_FILE_SIZE_A,size=TOTAL_NO_OF_FILES)\n",
    "\n",
    "\n",
    "\n",
    "class Simulation_Q():\n",
    "    def __init__(self):\n",
    "        self.q = []\n",
    "    \n",
    "    def push(self, event_tuple:tuple):\n",
    "        h.heappush(self.q,event_tuple)\n",
    "\n",
    "    def pop(self):\n",
    "        return h.heappop(self.q)[1]\n",
    "        \n",
    "class Cache():\n",
    "    def __init__(self,\n",
    "    all_files:Files,\n",
    "    init_file_list=[]):\n",
    "\n",
    "        self.capacity = CACHE_CAPACITY\n",
    "        self.store = {}\n",
    "        self.storage_left = CACHE_CAPACITY\n",
    "        self.all_files = all_files\n",
    "        self.__subclass_declarations__()\n",
    "        for i in range(len(init_file_list)):\n",
    "            if not self.add_file(init_file_list[i]):\n",
    "                break\n",
    "    \n",
    "    def __subclass_declarations__(self):\n",
    "        pass\n",
    "\n",
    "    def file_present(self,file_index):\n",
    "        if file_index in self.store:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "\n",
    "    def add_file(self,file_index):\n",
    "        if file_index not in self.store:\n",
    "            if self.storage_left > self.all_files.size[file_index]:\n",
    "                self.store[file_index] = self.all_files.size[file_index]\n",
    "                self.storage_left -= self.all_files.size[file_index]\n",
    "            else:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "# class LRU_cache(Cache):\n",
    "\n",
    "#     def __subclass_declerations__(self):\n",
    "#         self.use_heap = []\n",
    "#         self.hit_counter = 0\n",
    "\n",
    "\n",
    "#     def add_file()\n",
    "\n",
    "class LRU_File():\n",
    "    def __init__(self,file_index,file_size):\n",
    "        self.next = None\n",
    "        self.prev = None\n",
    "        self.id = file_index\n",
    "        self.size = file_size\n",
    "        self.hits = 0\n",
    "\n",
    "\n",
    "class LRU_Cache(Cache):\n",
    "    \n",
    "    def __subclass_declarations__(self):\n",
    "        self.lru_root = None\n",
    "        self.lru_tail = None\n",
    "        self.hit_counter = 0\n",
    "\n",
    "    def file_present(self,file_index):\n",
    "        if file_index in self.store:\n",
    "            file = self.store[file_index]\n",
    "            # self.hit_counter += 1\n",
    "            if file.prev is not None and file.next is not None:\n",
    "                file.prev.next = file.next\n",
    "                file.next.prev = file.prev\n",
    "                self.lru_tail.next = file\n",
    "                file.prev = self.lru_tail   \n",
    "                self.lru_tail = file\n",
    "                self.lru_tail.next = None\n",
    "            elif file.prev is None and file.next is not None:\n",
    "                self.lru_root = file.next\n",
    "                self.lru_root.prev = None\n",
    "                self.lru_tail.next = file\n",
    "                file.prev = self.lru_tail   \n",
    "                self.lru_tail = file\n",
    "                self.lru_tail.next = None\n",
    "            file.hits += 1\n",
    "            \n",
    "            # print(file_index,'R',self.get_lru_list())\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "\n",
    "    def add_file(self,file_index,increment_counter=True):    \n",
    "        if self.all_files.size[file_index] > CACHE_MAX_ALLOWED_FILE_SIZE or self.all_files.size[file_index] > CACHE_CAPACITY:\n",
    "            return False  \n",
    "        if file_index not in self.store:\n",
    "            file = LRU_File(file_index,self.all_files.size[file_index]) \n",
    "            # if increment_counter:\n",
    "            #     self.hit_counter += 1\n",
    "            if self.storage_left > self.all_files.size[file_index]:\n",
    "\n",
    "                if self.lru_root is None:\n",
    "                    self.lru_root = file\n",
    "                if self.lru_tail is None:\n",
    "                    self.lru_tail = file\n",
    "                else:\n",
    "                    self.lru_tail.next = file\n",
    "                    file.prev = self.lru_tail                    \n",
    "                    self.lru_tail = file\n",
    "                    self.lru_tail.next = None\n",
    "                self.store[file.id] = file\n",
    "                self.storage_left -= file.size\n",
    "                file.hits += 1\n",
    "\n",
    "            else:\n",
    "                while(self.storage_left <= file.size):\n",
    "                    if self.lru_root is None:\n",
    "                        raise Exception('LRU Cache - Storage inconsistency')                       \n",
    "\n",
    "                    file_to_discard = self.lru_root\n",
    "                    self.lru_root = file_to_discard.next\n",
    "                    if self.lru_root is None:\n",
    "                        self.lru_tail = None\n",
    "                    else:\n",
    "                        self.lru_root.prev = None\n",
    "                    del self.store[file_to_discard.id]\n",
    "                    self.storage_left += file_to_discard.size\n",
    "                self.add_file(file_index)\n",
    "\n",
    "            # print(file_index,'W',self.get_lru_list(),file.size)  \n",
    "        else:\n",
    "            self.file_present(file_index)        \n",
    "        \n",
    "        return True\n",
    "        \n",
    "\n",
    "    def get_stored_file_list(self):\n",
    "        file_list = []\n",
    "        for key in self.store:\n",
    "            file_list.append([self.store[key].id,self.store[key].hits])\n",
    "        return file_list\n",
    "\n",
    "    def get_lru_list(self):\n",
    "        file_list = []\n",
    "        node = self.lru_root\n",
    "        while(node is not None):\n",
    "            file_list.append(node.id)\n",
    "            node = node.next\n",
    "        return file_list\n",
    "\n",
    "\n",
    "    # def add_file(self,file_index,increment_counter=True):    \n",
    "    #     if self.all_files.size[file_index] > CACHE_MAX_ALLOWED_FILE_SIZE or self.all_files.size[file_index] > CACHE_CAPACITY:\n",
    "    #         return False  \n",
    "    #     if file_index not in self.store:            \n",
    "    #         if increment_counter:\n",
    "    #             self.hit_counter += 1\n",
    "    #         if self.storage_left > self.all_files.size[file_index]:\n",
    "    #             file_tuple = [self.hit_counter,self.all_files.size[file_index],file_index]\n",
    "    #             self.store[file_index] = file_tuple\n",
    "    #             h.heappush(self.lru_heap,file_tuple)\n",
    "    #             self.storage_left -= self.all_files.size[file_index]\n",
    "    #         else:\n",
    "    #             while(self.storage_left <= self.all_files.size[file_index]):\n",
    "    #                 file_tuple = h.heappop(self.lru_heap)                    \n",
    "    #                 del self.store[file_tuple[2]]\n",
    "    #                 self.storage_left += self.all_files.size[file_tuple[2]]\n",
    "    #             self.all_files(file_index,increment_counter=False)  \n",
    "    #     else:\n",
    "    #         self.file_present(self,file_index)\n",
    "    #     return True\n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "class Simulator_Env():\n",
    "    def __init__(self, Files:Files, Cache:Cache, cache_init_files=[]):\n",
    "\n",
    "        self.sim_q = Simulation_Q()\n",
    "        self.files = Files\n",
    "        self.cache = Cache\n",
    "        self.fifo = []\n",
    "        self.log = []\n",
    "        self.req_count = 0\n",
    "    \n",
    "    def get_total_times_for_reqs(self):\n",
    "        return(np.array(self.log)[:,0])\n",
    "\n",
    "\n",
    "class Event:\n",
    "\n",
    "    def __init__(self, sim: Simulator_Env, create_time: int, parent:object=None):\n",
    "        self.sim = sim\n",
    "        self.create_time = create_time\n",
    "        self.process_time = create_time\n",
    "        self.parent = parent\n",
    "        self.name = 'Event'\n",
    "        self.__enqueue__()\n",
    "\n",
    "    def get_super_parent(self):\n",
    "        node = self\n",
    "        while(node.parent is not None):\n",
    "            node = node.parent\n",
    "        return node\n",
    "\n",
    "    def __lt__(self,any):\n",
    "        return True\n",
    "\n",
    "    def __gt__(self,any):\n",
    "        return True\n",
    "\n",
    "    def __enqueue__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def process(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class E_get_new_reqs(Event):\n",
    "\n",
    "    def __enqueue__(self):\n",
    "        self.name = 'Get New Requests'\n",
    "        self.sim.sim_q.push([self.process_time,self])\n",
    "\n",
    "    def process(self):\n",
    "        reqs_to_handle = np.random.poisson(POISSON_PROCESS_NEW_REQUESTS_LAMBDA)\n",
    "        for i in range(int(reqs_to_handle)):\n",
    "            E_new_req(self.sim, self.process_time)\n",
    "\n",
    "\n",
    "class E_new_req(Event):\n",
    "    def __enqueue__(self):\n",
    "        self.name = 'New Request'\n",
    "        self.sim.req_count += 1\n",
    "        self.file_index = np.argmax(np.random.multinomial(1,self.sim.files.popularity))\n",
    "        self.file_size = self.sim.files.size[self.file_index]        \n",
    "        # self.process_time = self.create_time + (self.file_size/INSTITUTIONAL_BANDWIDTH)\n",
    "        self.sim.sim_q.push([self.process_time,self])\n",
    "\n",
    "    def process(self):\n",
    "        if sim.cache.file_present(self.file_index):\n",
    "            E_file_recieved(self.sim,self.process_time,self)\n",
    "        else:\n",
    "            E_arrive_at_queue(self.sim,self.process_time,self)\n",
    "\n",
    "\n",
    "class E_file_recieved(Event):\n",
    "    def __enqueue__(self):\n",
    "        self.name = 'File recieved'\n",
    "        initial_req = self.get_super_parent()\n",
    "        file_size = self.sim.files.size[initial_req.file_index]\n",
    "        self.process_time = self.create_time + (file_size/ INSTITUTIONAL_BANDWIDTH)\n",
    "        self.sim.sim_q.push([self.process_time,self])\n",
    "\n",
    "    def process(self):\n",
    "        initial_req = self.get_super_parent()\n",
    "        log_data = [self.process_time - initial_req.create_time, initial_req.file_index, initial_req.file_size,self]\n",
    "        self.sim.log.append(log_data)\n",
    "\n",
    "\n",
    "class E_arrive_at_queue(Event):\n",
    "    def __enqueue__(self):\n",
    "        self.name = 'Arrive at queue'\n",
    "        self.process_time = self.create_time + np.random.lognormal(LOGNORMAL_PROCESS_ARRIVE_AT_QUEUE_MEAN,\n",
    "                                                                    LOGNORMAL_PROCESS_ARRIVE_AT_QUEUE_SIGMA)\n",
    "        \n",
    "        self.sim.sim_q.push([self.process_time,self])\n",
    "\n",
    "    def process(self):\n",
    "        if len(self.sim.fifo):\n",
    "            self.sim.fifo.append(self)\n",
    "        else:\n",
    "            E_depart_from_queue(self.sim,self.process_time,self)\n",
    "\n",
    "\n",
    "class E_depart_from_queue(Event):\n",
    "    def __enqueue__(self):\n",
    "        self.name = 'Depart from queue'\n",
    "        initial_req = self.get_super_parent()\n",
    "        self.process_time = self.create_time + (initial_req.file_size/ACCESS_LINK_BANDWIDTH)\n",
    "        self.sim.sim_q.push([self.process_time,self])\n",
    "\n",
    "    def process(self):\n",
    "        initial_req = self.get_super_parent()\n",
    "        sim.cache.add_file(initial_req.file_index)\n",
    "        E_file_recieved(self.sim,self.process_time,self)\n",
    "        if len(sim.fifo):\n",
    "            event = sim.fifo.pop(0)\n",
    "            E_depart_from_queue(self.sim,self.process_time,event)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.6914901397315225"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POISSON_PROCESS_NEW_REQUESTS_LAMBDA = 100\n",
    "PARETO_PROCESS_NEW_FILE_SIZE_A = 2\n",
    "PARETO_PROCESS_FILE_POPULARITY_A = 1\n",
    "LOGNORMAL_PROCESS_ARRIVE_AT_QUEUE_MEAN = 0.5\n",
    "LOGNORMAL_PROCESS_ARRIVE_AT_QUEUE_SIGMA = 0.4\n",
    "\n",
    "TOTAL_NO_OF_FILES = 10000\n",
    "INSTITUTIONAL_BANDWIDTH = 1000\n",
    "ACCESS_LINK_BANDWIDTH = 15\n",
    "TOTAL_TIME_TO_RUN = 100\n",
    "CACHE_CAPACITY = 10\n",
    "CACHE_MAX_ALLOWED_FILE_SIZE = 10\n",
    "\n",
    "\n",
    "# initialize simulator environment\n",
    "# np.random.seed(11)\n",
    "files = Files()\n",
    "cache = LRU_Cache(files)\n",
    "# cache = Cache(files)\n",
    "sim = Simulator_Env(files,cache)\n",
    "\n",
    "#initialize new req events to be processed at every second\n",
    "for i in range(TOTAL_TIME_TO_RUN):\n",
    "    E_get_new_reqs(sim,i)\n",
    "\n",
    "\n",
    "#Main simulator loop\n",
    "while(len(sim.sim_q.q)):\n",
    "\n",
    "    e = sim.sim_q.pop()\n",
    "    e.process()\n",
    "    \n",
    "    \n",
    "\n",
    "print(len(sim.log) == sim.req_count)\n",
    "\n",
    "#Show logs\n",
    "# for data in sim.log:    \n",
    "#     e = data[3]\n",
    "#     path = []\n",
    "#     while(e is not None):\n",
    "#         path.insert(0,e.name)\n",
    "#         e = e.parent\n",
    "#     print('file name - ' + str(data[1]))    \n",
    "#     print('file size - ' + str(data[2]))\n",
    "#     print('total time - ' + str(data[0]))\n",
    "#     print(path)\n",
    "#     print(' ')\n",
    "np.mean(sim.get_total_times_for_reqs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2407, 1]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache.get_stored_file_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9578999703034629"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "np.mean(sim.get_total_times_for_reqs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "\n",
    "    return(1/(1 + np.exp(-x)))\n",
    "\n",
    "sigmoid(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x1526c4afeb0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.displot(np.random.pareto(1,size=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0917191290613566"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.random.pareto(2,size=1000))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0ca4fa896740cdf9b5278ecd42212927da2ae9b32b6ec5699b862edf50dd507e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
