{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq as h\n",
    "import numpy as np\n",
    "\n",
    "POISSON_PROCESS_NEW_REQUESTS_LAMBDA = 100\n",
    "PARETO_PROCESS_NEW_FILE_SIZE_A = 1\n",
    "PARETO_PROCESS_FILE_POPULARITY_A = 1\n",
    "LOGNORMAL_PROCESS_ARRIVE_AT_QUEUE_MEAN = 0.5\n",
    "LOGNORMAL_PROCESS_ARRIVE_AT_QUEUE_SIGMA = 0.4\n",
    "\n",
    "TOTAL_NO_OF_FILES = 1000\n",
    "INSTITUTIONAL_BANDWIDTH = 1000\n",
    "ACCESS_LINK_BANDWIDTH = 15\n",
    "TOTAL_TIME_TO_RUN = 1000\n",
    "CACHE_CAPACITY = 10\n",
    "CACHE_MAX_ALLOWED_FILE_SIZE = 10\n",
    "\n",
    "\n",
    "class Files:\n",
    "    def __init__(self):\n",
    "        self.popularity = np.random.pareto(PARETO_PROCESS_FILE_POPULARITY_A,size=TOTAL_NO_OF_FILES)\n",
    "        self.popularity = self.popularity/np.sum(self.popularity)\n",
    "        self.size = np.random.pareto(PARETO_PROCESS_NEW_FILE_SIZE_A,size=TOTAL_NO_OF_FILES)\n",
    "\n",
    "\n",
    "\n",
    "class Simulation_Q():\n",
    "    def __init__(self):\n",
    "        self.q = []\n",
    "    \n",
    "    def push(self, event_tuple:tuple):\n",
    "        h.heappush(self.q,event_tuple)\n",
    "\n",
    "    def pop(self):\n",
    "        return h.heappop(self.q)[1]\n",
    "        \n",
    "class Cache():\n",
    "    def __init__(self,\n",
    "    all_files:Files,\n",
    "    init_file_list=[]):\n",
    "\n",
    "        self.capacity = CACHE_CAPACITY\n",
    "        self.store = {}\n",
    "        self.storage_left = CACHE_CAPACITY\n",
    "        self.all_files = all_files\n",
    "        self.__subclass_declarations__()\n",
    "        for i in range(len(init_file_list)):\n",
    "            if not self.add_file(init_file_list[i]):\n",
    "                break\n",
    "    \n",
    "    def __subclass_declarations__(self):\n",
    "        pass\n",
    "\n",
    "    def file_present(self,file_index):\n",
    "        if file_index in self.store:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "\n",
    "    def add_file(self,file_index):\n",
    "        if file_index not in self.store:\n",
    "            if self.storage_left > self.all_files.size[file_index]:\n",
    "                self.store[file_index] = self.all_files.size[file_index]\n",
    "                self.storage_left -= self.all_files.size[file_index]\n",
    "            else:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "\n",
    "class LRU_File():\n",
    "    def __init__(self,file_index,file_size):\n",
    "        self.next = None\n",
    "        self.prev = None\n",
    "        self.id = file_index\n",
    "        self.size = file_size\n",
    "        self.hits = 0\n",
    "\n",
    "\n",
    "class LRU_Cache(Cache):\n",
    "    \n",
    "    def __subclass_declarations__(self):\n",
    "        self.lru_root = None\n",
    "        self.lru_tail = None\n",
    "        self.hit_counter = 0\n",
    "\n",
    "    def file_present(self,file_index):\n",
    "        if file_index in self.store:\n",
    "            file = self.store[file_index]\n",
    "            # self.hit_counter += 1\n",
    "            if file.prev is not None and file.next is not None:\n",
    "                file.prev.next = file.next\n",
    "                file.next.prev = file.prev\n",
    "                self.lru_tail.next = file\n",
    "                file.prev = self.lru_tail   \n",
    "                self.lru_tail = file\n",
    "                self.lru_tail.next = None\n",
    "            elif file.prev is None and file.next is not None:\n",
    "                self.lru_root = file.next\n",
    "                self.lru_root.prev = None\n",
    "                self.lru_tail.next = file\n",
    "                file.prev = self.lru_tail   \n",
    "                self.lru_tail = file\n",
    "                self.lru_tail.next = None\n",
    "            file.hits += 1\n",
    "            \n",
    "            # print(file_index,'R',self.get_lru_list())\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "\n",
    "    def add_file(self,file_index):    \n",
    "        if self.all_files.size[file_index] > CACHE_MAX_ALLOWED_FILE_SIZE or self.all_files.size[file_index] > CACHE_CAPACITY:\n",
    "            return False  \n",
    "        if file_index not in self.store:\n",
    "            file = LRU_File(file_index,self.all_files.size[file_index]) \n",
    "            # if increment_counter:\n",
    "            #     self.hit_counter += 1\n",
    "            if self.storage_left > self.all_files.size[file_index]:\n",
    "\n",
    "                if self.lru_root is None:\n",
    "                    self.lru_root = file\n",
    "                if self.lru_tail is None:\n",
    "                    self.lru_tail = file\n",
    "                else:\n",
    "                    self.lru_tail.next = file\n",
    "                    file.prev = self.lru_tail                    \n",
    "                    self.lru_tail = file\n",
    "                    self.lru_tail.next = None\n",
    "                self.store[file.id] = file\n",
    "                self.storage_left -= file.size\n",
    "                file.hits += 1\n",
    "\n",
    "            else:\n",
    "                while(self.storage_left <= file.size):\n",
    "                    if self.lru_root is None:\n",
    "                        raise Exception('LRU Cache - Storage inconsistency')                       \n",
    "\n",
    "                    file_to_discard = self.lru_root\n",
    "                    self.lru_root = file_to_discard.next\n",
    "                    if self.lru_root is None:\n",
    "                        self.lru_tail = None\n",
    "                    else:\n",
    "                        self.lru_root.prev = None\n",
    "                    del self.store[file_to_discard.id]\n",
    "                    self.storage_left += file_to_discard.size\n",
    "                self.add_file(file_index)\n",
    "\n",
    "            # print(file_index,'W',self.get_lru_list(),file.size)  \n",
    "        else:\n",
    "            self.file_present(file_index)        \n",
    "        \n",
    "        return True\n",
    "        \n",
    "\n",
    "    def get_stored_file_list(self):\n",
    "        file_list = []\n",
    "        for key in self.store:\n",
    "            file_list.append([self.store[key].id,self.store[key].hits])\n",
    "        return file_list\n",
    "\n",
    "    def get_lru_list(self):\n",
    "        file_list = []\n",
    "        node = self.lru_root\n",
    "        while(node is not None):\n",
    "            file_list.append(node.id)\n",
    "            node = node.next\n",
    "        return file_list\n",
    "\n",
    "\n",
    "         \n",
    "\n",
    "\n",
    "\n",
    "class Simulator_Env():\n",
    "    def __init__(self, Files:Files, Cache:Cache, cache_init_files=[]):\n",
    "\n",
    "        self.sim_q = Simulation_Q()\n",
    "        self.files = Files\n",
    "        self.cache = Cache\n",
    "        self.fifo = []\n",
    "        self.log = []\n",
    "        self.req_count = 0\n",
    "        self.queue_delays = []\n",
    "    \n",
    "    def get_total_times_for_reqs(self):\n",
    "        return(np.array(self.log)[:,0])\n",
    "\n",
    "    def print_logs(self):\n",
    "        for data in self.log:    \n",
    "            e = data[3]\n",
    "            path = []\n",
    "            while(e is not None):\n",
    "                path.insert(0,e.name)\n",
    "                e = e.parent\n",
    "            print('file name - ' + str(data[1]))    \n",
    "            print('file size - ' + str(data[2]))\n",
    "            print('total time - ' + str(data[0]))\n",
    "            print(path)\n",
    "            print(' ')\n",
    "\n",
    "\n",
    "class Event:\n",
    "\n",
    "    def __init__(self, sim: Simulator_Env, create_time: int, parent:object=None):\n",
    "        self.sim = sim\n",
    "        self.create_time = create_time\n",
    "        self.process_time = create_time\n",
    "        self.parent = parent\n",
    "        self.name = 'Event'\n",
    "        self.__enqueue__()\n",
    "\n",
    "    def get_super_parent(self):\n",
    "        node = self\n",
    "        while(node.parent is not None):\n",
    "            node = node.parent\n",
    "        return node\n",
    "\n",
    "    def __lt__(self,any):\n",
    "        return True\n",
    "\n",
    "    def __gt__(self,any):\n",
    "        return True\n",
    "\n",
    "    def __enqueue__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def process(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class E_get_new_reqs(Event):\n",
    "\n",
    "    def __enqueue__(self):\n",
    "        self.name = 'Get New Requests'\n",
    "        self.sim.sim_q.push([self.process_time,self])\n",
    "\n",
    "    def process(self):\n",
    "        reqs_to_handle = np.random.poisson(POISSON_PROCESS_NEW_REQUESTS_LAMBDA)\n",
    "        for i in range(int(reqs_to_handle)):\n",
    "            E_new_req(self.sim, self.process_time)\n",
    "\n",
    "\n",
    "class E_new_req(Event):\n",
    "    def __enqueue__(self):\n",
    "        self.name = 'New Request'\n",
    "        self.sim.req_count += 1\n",
    "        self.file_index = np.argmax(np.random.multinomial(1,self.sim.files.popularity))\n",
    "        self.file_size = self.sim.files.size[self.file_index]        \n",
    "        # self.process_time = self.create_time + (self.file_size/INSTITUTIONAL_BANDWIDTH)\n",
    "        self.sim.sim_q.push([self.process_time,self])\n",
    "\n",
    "    def process(self):\n",
    "        if self.sim.cache.file_present(self.file_index):\n",
    "            E_file_recieved(self.sim,self.process_time,self)\n",
    "        else:\n",
    "            E_arrive_at_queue(self.sim,self.process_time,self)\n",
    "\n",
    "\n",
    "class E_file_recieved(Event):\n",
    "    def __enqueue__(self):\n",
    "        self.name = 'File recieved'\n",
    "        initial_req = self.get_super_parent()\n",
    "        file_size = self.sim.files.size[initial_req.file_index]\n",
    "        self.process_time = self.create_time + (file_size/ INSTITUTIONAL_BANDWIDTH)\n",
    "        self.sim.sim_q.push([self.process_time,self])\n",
    "\n",
    "    def process(self):\n",
    "        initial_req = self.get_super_parent()\n",
    "        log_data = [self.process_time - initial_req.create_time, initial_req.file_index, initial_req.file_size,self]\n",
    "        self.sim.log.append(log_data)\n",
    "\n",
    "\n",
    "class E_arrive_at_queue(Event):\n",
    "    def __enqueue__(self):\n",
    "        self.name = 'Arrive at queue'\n",
    "        self.process_time = self.create_time + np.random.lognormal(LOGNORMAL_PROCESS_ARRIVE_AT_QUEUE_MEAN,\n",
    "                                                                    LOGNORMAL_PROCESS_ARRIVE_AT_QUEUE_SIGMA)\n",
    "        \n",
    "        self.sim.sim_q.push([self.process_time,self])\n",
    "\n",
    "    def process(self):\n",
    "        self.sim.fifo.append(self)\n",
    "        if len(self.sim.fifo) < 2:\n",
    "            E_depart_from_queue(self.sim,self.process_time,self)\n",
    "\n",
    "\n",
    "class E_depart_from_queue(Event):\n",
    "    def __enqueue__(self):\n",
    "        self.name = 'Depart from queue'\n",
    "        initial_req = self.get_super_parent()\n",
    "        self.process_time = self.create_time + (initial_req.file_size/ACCESS_LINK_BANDWIDTH)\n",
    "        self.sim.sim_q.push([self.process_time,self])\n",
    "        self.queue_delay = 0\n",
    "        if isinstance(self.parent, E_arrive_at_queue):\n",
    "            self.queue_delay = self.create_time - self.parent.process_time\n",
    "            # print(self.queue_delay)\n",
    "        self.sim.queue_delays.append(self.queue_delay)\n",
    "\n",
    "\n",
    "    def process(self):\n",
    "        initial_req = self.get_super_parent()\n",
    "        self.sim.cache.add_file(initial_req.file_index)\n",
    "        E_file_recieved(self.sim,self.process_time,self)\n",
    "        self.sim.fifo.pop(0)\n",
    "        if len(self.sim.fifo):\n",
    "            E_depart_from_queue(self.sim,self.process_time,self.sim.fifo[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRU_Cache(Cache):\n",
    "    \n",
    "    def __subclass_declarations__(self):\n",
    "        self.mru_root = None\n",
    "        # self.lru_tail = None\n",
    "        self.hit_counter = 0\n",
    "\n",
    "    def file_present(self,file_index):\n",
    "        if file_index in self.store:\n",
    "            file = self.store[file_index]\n",
    "            # self.hit_counter += 1\n",
    "\n",
    "            if file.prev is not None:                \n",
    "                file.prev.next = file.next\n",
    "                if file.next is not None:\n",
    "                    file.next.prev = file.prev\n",
    "\n",
    "                file.next = self.mru_root\n",
    "                self.mru_root.prev = file\n",
    "                self.mru_root = file\n",
    "                self.mru_root.prev = None\n",
    "                \n",
    "            file.hits += 1\n",
    "            \n",
    "            # print(file_index,'R',self.get_mru_list())\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "\n",
    "    def add_file(self,file_index):    \n",
    "        if self.all_files.size[file_index] > CACHE_MAX_ALLOWED_FILE_SIZE or self.all_files.size[file_index] > CACHE_CAPACITY:\n",
    "            return False  \n",
    "        if file_index not in self.store:\n",
    "            file = LRU_File(file_index,self.all_files.size[file_index]) \n",
    "            # if increment_counter:\n",
    "            #     self.hit_counter += 1\n",
    "            if self.storage_left > self.all_files.size[file_index]:\n",
    "\n",
    "                if self.mru_root is None:\n",
    "                    self.mru_root = file\n",
    "                else:\n",
    "                    file.next = self.mru_root\n",
    "                    self.mru_root.prev = file\n",
    "                    self.mru_root = file\n",
    "                    self.mru_root.prev = None\n",
    "                self.store[file.id] = file\n",
    "                self.storage_left -= file.size\n",
    "                file.hits += 1\n",
    "\n",
    "            else:\n",
    "                while(self.storage_left <= file.size):\n",
    "                    if self.mru_root is None:\n",
    "                        raise Exception('LRU Cache - Storage inconsistency')                       \n",
    "\n",
    "                    file_to_discard = self.mru_root\n",
    "                    self.mru_root = file_to_discard.next\n",
    "                    if self.mru_root is not None:\n",
    "                        self.mru_root.prev = None\n",
    "                    del self.store[file_to_discard.id]\n",
    "                    self.storage_left += file_to_discard.size\n",
    "                self.add_file(file_index)\n",
    "\n",
    "            # print(file_index,'W',self.get_mru_list(),file.size)  \n",
    "        else:\n",
    "            self.file_present(file_index)        \n",
    "        \n",
    "        return True\n",
    "\n",
    "\n",
    "\n",
    "    def get_stored_file_list(self):\n",
    "        file_list = []\n",
    "        for key in self.store:\n",
    "            file_list.append([self.store[key].id,self.store[key].hits])\n",
    "        return file_list\n",
    "\n",
    "    def get_mru_list(self):\n",
    "        file_list = []\n",
    "        node = self.mru_root\n",
    "        while(node is not None):\n",
    "            file_list.append(node.id)\n",
    "            node = node.next\n",
    "        return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "9762\n",
      "1.7297990665956373\n",
      "1.180207539501058\n"
     ]
    }
   ],
   "source": [
    "POISSON_PROCESS_NEW_REQUESTS_LAMBDA = 100\n",
    "PARETO_PROCESS_NEW_FILE_SIZE_A = 2\n",
    "PARETO_PROCESS_FILE_POPULARITY_A = 1\n",
    "LOGNORMAL_PROCESS_ARRIVE_AT_QUEUE_MEAN = 0.5\n",
    "LOGNORMAL_PROCESS_ARRIVE_AT_QUEUE_SIGMA = 0.4\n",
    "\n",
    "TOTAL_NO_OF_FILES = 10000\n",
    "INSTITUTIONAL_BANDWIDTH = 1000\n",
    "ACCESS_LINK_BANDWIDTH = 50\n",
    "TOTAL_TIME_TO_RUN = 100\n",
    "CACHE_CAPACITY = 50\n",
    "CACHE_MAX_ALLOWED_FILE_SIZE = 20\n",
    "\n",
    "\n",
    "# initialize simulator environment\n",
    "# np.random.seed(11)\n",
    "files = Files()\n",
    "cache = LRU_Cache(files)\n",
    "# cache = Cache(files)\n",
    "\n",
    "sim = Simulator_Env(files,cache)\n",
    "\n",
    "#initialize new req events to be processed at every second\n",
    "for i in range(TOTAL_TIME_TO_RUN):\n",
    "    E_get_new_reqs(sim,i)\n",
    "\n",
    "\n",
    "#Main simulator loop\n",
    "while(len(sim.sim_q.q)):\n",
    "\n",
    "    e = sim.sim_q.pop()\n",
    "    e.process()\n",
    "    \n",
    "\n",
    "print(len(sim.log) == sim.req_count)\n",
    "\n",
    "print(sim.req_count)\n",
    "print(np.mean(sim.get_total_times_for_reqs()))\n",
    "print(np.mean(sim.queue_delays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "\n",
    "    return(1/(1 + np.exp(-x)))\n",
    "\n",
    "sigmoid(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x11512c7efa0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "def pareto(a,m,samples):\n",
    "    return((np.random.pareto(a, samples) + 1) * m)\n",
    "\n",
    "s = pareto(3,1,1000)\n",
    "sns.displot(s[s<5])\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0ca4fa896740cdf9b5278ecd42212927da2ae9b32b6ec5699b862edf50dd507e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
